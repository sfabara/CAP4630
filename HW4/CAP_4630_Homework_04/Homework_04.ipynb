{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LwvvMtG18SK"
   },
   "source": [
    "# Recurrent Neural Network Homework\n",
    "\n",
    "This is the 4th assignment for CAP 4630 and we will implement a basic RNN network and an LSTM network with Keras to solve two problems. \\\n",
    "You will use **\"Tasks\"** and **\"Hints\"** to finish the work. **(Total 100 points, including 15 bonus points)** \\\n",
    "You may use Machine Learning libaries like Scikit-learn for data preprocessing.\n",
    "\n",
    "**Task Overview:**\n",
    "- Implement a basic RNN network to solve time series prediction \n",
    "- Implement an LSTM network to conduct sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l24oSrIK18SL"
   },
   "source": [
    "## 1 - Implement Basic RNN network with Keras to predict time series##\n",
    "### 1.1 Prepare the data (17 Points)\n",
    "\n",
    "Prepare time series data for deep neural network training.\n",
    "\n",
    "**Tasks:**\n",
    "1. Load the given train and test data: \"train.txt\" and \"test.txt\". **(5 Points)**\n",
    "2. Generate the **TRAIN** and **TEST** labels. **(5 Points)**\n",
    "3. Normalize the **TRAIN** and **TEST** data with sklearn function \"MinMaxScaler\". **(5 Points)**\n",
    "4. **PRINT OUT** the **TEST** data and label. **(2 Points)**\n",
    "\n",
    "**Hints:**  \n",
    "1. The length of original train data is 113 which starts from **\"1949-01\"** to **\"1958-05\"**. The length of original test data is 29, which starts from **\"1958-07\"** to **\"1960-11\"**. \n",
    "2. Set the data types of both train and test data to \"float32\". \n",
    "3. When you prepared input data X (sequences) and oupt data Y (labels), please consider the following relationship:\n",
    "    - The sequence X should be the **past 12** datapoints in the time series, i.e., observation sequence with historical window of 12. You may check the time series data and think about the reason.\n",
    "    - The label Y should be the **next 1** datapoint in the time series (one point ahead prediction).\n",
    "4. The first 3 **TRAIN** data and label should be:\n",
    "\n",
    "- trainX[0] = [[0.02203858 &nbsp; 0.03856748 &nbsp; 0.077135 &nbsp;  0.06887051 &nbsp; 0.04683197 &nbsp; 0.08539945 &nbsp; 0.12121212 &nbsp; 0.12121212 &nbsp; 0.08815429 &nbsp; 0.04132232 &nbsp; 0.    &nbsp; 0.03856748]]\n",
    "- trainY[0] = [0.03030303]\n",
    "\n",
    "- trianX[1] = [[0.03856748 &nbsp; 0.077135 &nbsp;  0.06887051 &nbsp; 0.04683197  &nbsp; 0.08539945  &nbsp; 0.12121212  &nbsp; 0.12121212  &nbsp; 0.08815429  &nbsp; 0.04132232  &nbsp; 0.     &nbsp;  0.03856748   &nbsp; 0.03030303]]\n",
    "- trainY[1] = [0.06060606]\n",
    "\n",
    "- trainX[2] =  [[0.077135 &nbsp;  0.06887051 &nbsp; 0.04683197 &nbsp; 0.08539945 &nbsp; 0.12121212 &nbsp; 0.12121212 &nbsp; 0.08815429 &nbsp; 0.04132232 &nbsp; 0.    &nbsp;     0.03856748 &nbsp; 0.03030303 &nbsp; 0.06060606]]\n",
    "- trainY[2] = [0.10192838]\n",
    "\n",
    "5. Apply the MinMaxScaler to both the train and test data.\\\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "\n",
    "\n",
    "6. After the preparation with scaler fitting, the shapes of trainX, trainY, testX, and testY are as follows:\\\n",
    "trainX.shape = (101, 1, 12)\\\n",
    "trainY.shape = (101,)\\\n",
    "testX.shape = (17, 1, 12)\\\n",
    "testY.shape = (17,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hS7xhrC3-_-1"
   },
   "outputs": [],
   "source": [
    "### Import Libraries ###\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers \n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "### Set random seed to ensure deterministic results\n",
    "import os\n",
    "seed_value = 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(seed_value)\n",
    "   np.random.seed(seed_value)\n",
    "   random.seed(seed_value)\n",
    "reset_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shAj2Y6IuxUv"
   },
   "outputs": [],
   "source": [
    "### Prepare and Preprocess Data Here ###\n",
    "from pandas import read_csv\n",
    "\n",
    "### Design a Function to Prepare Observation Sequences and Corresponding Labels ###\n",
    "\n",
    "# def create_dataset(dataset, look_back=12): # look_back is used to specify input sequence length\n",
    "# \tdataX, dataY = [], []\n",
    "# \tfor i in range(len(dataset)-look_back):\n",
    "# \t\tdataX.append(...) \n",
    "# \t\tdataY.append(...)\n",
    "# \treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "### Train and Test Data Loading with float32 type ####\n",
    "# dataframe_train = read_csv('train.txt', usecols=[1], engine='python') # Read train.txt \n",
    "# dataset_train = dataframe_train.values\n",
    "# dataset_train = dataset_train.astype('float32') # Specify the data type to 'float32'\n",
    "\n",
    "\n",
    "\n",
    "### Scale Training and Test Data to [0, 1] ###\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1)) # specify the scaler\n",
    "# train = scaler.fit_transform(...) # fit the scaler to the training data\n",
    "# test = scaler.transform(...) # fit the scaler to the test data\n",
    "\n",
    "### Training and Test Data Split ###\n",
    "# trainX, trainY = create_dataset(..., look_back=...)\n",
    "# testX, testY = ...\n",
    "\n",
    "### Training and Test Data Reshape (to fit RNN input) ###\n",
    "# trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "# testX = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQ1uHWzX8wlH",
    "outputId": "be610d58-7436-49b9-f39e-e524606772c4"
   },
   "outputs": [],
   "source": [
    "### Print Out the TEST Data and Labels Here ###\n",
    "# print(testX)\n",
    "# print(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AlakqA_vuFb"
   },
   "source": [
    "### 1.2 - Build the RNN model (20 Points) ##\n",
    "\n",
    "\n",
    "Build an RNN model with SimpleRNN cell. \n",
    "\n",
    "**Tasks:**\n",
    "1. Build an RNN model with 1 RNN layer and 1 Dense layer.  **(10 Points)**\n",
    "2. Compile the model. **(5 Points)**\n",
    "3. Train the model for **1000** epochs with **batch_size = 10**. **(5 Points)**\n",
    "\n",
    "**Hints:**  \n",
    "1. You may consider **tensorflow.keras.layers.SimpleRNN(unit_size=4)** to specify RNN cells.\n",
    "2. Use loss function = 'mean_squared_error' and select **Adam** optimizer with **learning_rate=0.005** and other default settings.\n",
    "3. After first epoch, the train loss is changed to around **0.0912**. \n",
    "4. The model summary is as follows:\n",
    "- Total params: 73\n",
    "- Trainable params: 73\n",
    "- Non-trainable params: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jn92qh8oyq0B"
   },
   "outputs": [],
   "source": [
    "### Build the RNN Model ###\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# model = Sequential() # Declare Sequential class and assign it to variable \"model\"\n",
    "# model.add(keras.layers.SimpleRNN( )) # Add a simple RNN layer with unit_size=4 in the model \n",
    "# model.add(keras.layers.Dense( )) # Add a following Dense layer with units=1 in the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnO-5WT-3hgH"
   },
   "outputs": [],
   "source": [
    "### Compile the RNN Model  ###\n",
    "\n",
    "# opt = keras.optimizers.Adam(learning_rate=...)\n",
    "# model.compile(...) # model compiled with mean_squared_error loss and adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tpZAutlzify",
    "outputId": "c95a034c-97c1-465e-b41c-3de52eea6d81"
   },
   "outputs": [],
   "source": [
    "### Train the RNN Model  ###\n",
    "\n",
    "# model.fit(...) # model fit with epoch=1000, batch_size=10; verbose=2 is optional.\n",
    "# model.summary() # print out model structure with model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dd2jZl4n0H8m"
   },
   "source": [
    "### 1.3 Evaluate Predictive Model Performance (10 Points)\n",
    "\n",
    "Predict datapoints with the observed datapoints and trained model. \n",
    "\n",
    "**Tasks:**\n",
    "1. Do direct prediction on train and test datapoints with the obtained model in section 1.2. **(2 Points)**\n",
    "2. Scale the prediction results back to original representation with the scaler. **(3 Points)**\n",
    "3. Calculate root mean squared error (RMSE) and **print out** the error for **both TRAIN and TEST**. **(3 Points)**\n",
    "4. **Plot** the **TEST** label and prediction. **(2 Points)**\n",
    "\n",
    "\n",
    "**Hints:**  \n",
    "1. Scale back the predictions with the build-in function \"scaler.inverse_transform\".\\\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler.inverse_transform\n",
    "2. For validation: Train Score: **~10.92 RMSE** Test Score: **~27.70 RMSE**\n",
    "3. The plot for validation is shown below (observation test data are blue and prediction results are orange):\n",
    "\n",
    "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAgAElEQVR4nO3d93sU1/U/8PwFxIntlE++ZugYB1fcO4l7j21wI05sYzsuuNsjJECoIJkiiugdRBW9zK56r6iBGipICAkV1MuqbJt5f3+4kkCWVnXKlvN6nvM89uxq56JydvbOvef87ne/+x0oKCgoKJwuNB8ABQUFBYX8ofkAKCgoKCjkD80HQEFBQUEhf2g+AAoKCgoK+UPzAVBQUFBQyB+aDwA333wzZs2aRUFBQUExgrD75D5r1iwQQggZGUruhBDihCi5E0KIE6LkTgghToiSOyGEOCFK7oQQ4oQouRNCiBOi5E4IIU6IkjshRBWnzlfiUm2b1sNwGZTcCSGKK7rWBo4XMMVdhxWhBegyW7UektOj5E4IUdymmBJwvIAv92eC4wU8sTwasUV1Wg/LqVFyJ4Qo7u3NSXg5MB4AkHSpHrNXxoDjBXx1IBO1rV0aj845UXInhCiqqd2EiW4CAsKLeo8ZLVasjSjGVA89Zi4JRVByGayipOEonQ8ld0KIok6drwTHCzhf0dzvscv17Xh/ewo4XsBrGxKRV9WiwQidEyV3QoiiFhzMwiyfcIg2rswlScLJrErM8gnHpIU6+JzNR7vRovIonQ8ld0KIYixWEXd6huKnIxeGfG5Lhxlux3PA8QIe8YtEWF6NCiN0XpTcCSGKSS1tAMcLCMmtHvbXpJc14rnVceB4AfP3pqOquVPBETovSu6EEMX46S9iirsOhhFOs5itIjbFlGD6Ij1mLA7B9vhSWKyiQqN0TpTcCSGKeSYgFh9sTx3111c0duC/u86B4wW8uDZ+wJuyZGCU3Akhiihv6ADHC9iZcHlMryNJEnQ51XhwWQQmuAlYfCoXrV1mmUbpvCi5E0IUsTvxMjhewJWGdller63LDM/TeZjgJuB+3whaNjkESu6EEEXM25GKf6yKkf11s6824+9LQuF2PFv213YmlNwJIbJrN1ow1V2PZbqLirz+/L3peGJ5tCKv7SwouRNCZBeaVwOOF5Bc0qDI6/dM+VQ0dijy+s6AkjshRHa/HM3GTM9QmBVavljcXUL40LlyRV7fGdh9ch8/frzW3yNCyAiIooT7fSPw1YFMxc4hSRIe8I3A1wezFDuHo7P75E5X7oQ4luyrzeB4ASeyrip6nu8On8d93rZr1rg6Su6EEFmtiSjCBDcBje0mRc9zJL0CHC/gYnWroudxVJTcCSGyenV9At7clKT4eaqaO8HxArbHlyp+LkdEyZ0QIpva1i5wvIAN0ZdUOd/slTH4aHeaKudyNJTcCSGyOZxWDo4XUFCjzlSJx8kc3LE4RLFVOY6MkjshRDaf7k3Ho/5RkCR1bnLqc6rB8QLSyxpVOZ8joeROCJGF0WLFjMUh8DiZo9o5mztMmOAmYG1EsWrndBSU3AkhsogrqgPHC4guqFX1vK8EJmDO5mRVz+kIKLkTQmTheToP0xfp0WW2qnrenoYgHSbqu3ojSu6EkDGTJAmPL4/CJ3vUX7kSX8w+McQUqvuJwd5RcieEjFlPrZcDqerXeuk0WTHVXQ9fIV/1c9szSu6EkDHbElsCjhdQ3aJNM+t3tibjxbXxmpzbXlFyJ4SM2Zwt2ibX9VHF4HjlSx44EkruhJAxae4wYdJCHVaFFWo2hszyJnC8ACG7WrMx2BtK7oSQMTl1vhIcLyCrvEmzMVisImYuCYXbcfXW2Ns7Su6EkDH59lCWXZTe/WRPGp5cQa33elByJ4SMmsUq4m6vMPwQfEHroWAXtd7rg5I7IWTU0soawfECdDnaz3UXdS/HPJxGrfcASu6EkDHw1xdg8kId2rrMWg8FksTa+y2g1nsAKLkTQsbg2dWxeH97itbD6PXtoSzM8olQrSqlPaPkTggZlYrGjpF1QqrJAZrKAAUTb3B3673CmjbFzuEoKLkTQkZlb3IZOF7A5fr2oZ/cUAIsvQnwHAesnAYEfwikbAaqsgCrfAW/Krtb7+1IuCzbazoqSu6EkFH5cOc5zF4ZM7wnh3kAXn8EktYDRz8GVv+dJXrPcYDvX4G9rwHRfkBJNGA0jGlcT62IxsfUeo+SOyFk5NqNFkx118Pn7DCKdZm7gF8nAIfn9T3echXIOQoIPwKbHgM8f8+S/dI/AFueAPS/AHkngNaRrcRxP5GDvy8JdfnWe5TcCSEjFpZXA44XkFRSP/STs4+wpF0SNfjzulqASxFAlA+w+2XA58/Xr+7X3Akc/wxI3wnUXgRE24lb1916L+OKa7feo+ROCBkxt+PZmDncq+NdLwJr7x40IQ/IagYqM4DkDcDhD4AVU64n+1854FLkgF/W1M5a762LdO3We5TcCSEjIkkSHvCNwJf7M4d+cm0BS8YJa+Q4Mbsxe/4Au5Lf/LjNlTcvB8Zj7hbXbr1HyZ0QMiK5lS3geAHHMq4O/WQ9D3jdDBjq5B1E+i72plGWOODDfrqLmOqud+nWe5TcCSEjsjaiGBPcBDQYjIM/0dwJ+N8GHP1I/kGYO9lN2kPvD/hwbHez7tgimd9UHAgl90FIkoTM8iYsOJiFR/2jUNWsTZcZQuzJa+sT8K+NA18x93H+ALu6vqxQE49Ib7bCprH/JqoOE1vN46e7qMy5HQAl9wEYLVYcy7iKV9cngOMF3LE4BBwvICjliupjIcSe1LUZwfEC1kcN42bl9meAwFnK7Uhtq2FTPvpfBnx47pZkvBzouq33KLnfoKalC6vCCjHLJxwcL+Afq2IQlFwGg9GCR/2j8FlQumpjIcQe9Wzvz69qHfyJNbnsqj15g7IDOv4ZsOz/2DLK31gXyaaPmly09Z7LJ3dJkpBe1oivDmRi8kIdJrgJ+GRPGuKL6/oUH+KPZWOmZygsLr4xgri2z4My8LBf5NCFuYQfAO9bgQ6F15pXnWdvIknr+z2UccV+yhFrwWWTe5fZiiPpFXhpXTw4XsBMz1D4nM1HecPAhf7PZleB4wVkathKjBAtGS1W3LE4BO4nhmhlZzQAy/7GrqrVsOtFYPXMfjVqzFYRf18SOvR4nZTLJfeq5k4sDynAvd5s6uWZgFjsS7mCduPgS6YauzdGBLr4xgjiuuKL2QqUyIvXBn9ixh52NV2uUingi2fZ+fJO9nvo491peHq49W+cjEskd0mScO5yI77Yn4FJC3WY6Cbg073pSLpUP6K6zy8HxmOOi2+MIK5r6Zk8TPPQo9NkHfyJW58CNjykaGnfPkQrsPYuYMez/R7akcBa71W64Eo3u0/u48ePH/U/rstsxeG0crywlk293LU0DH66i6PuseivL8AUd92QV/mEOBtJkvDE8mh8NFS1xaosdhWdulWdgfVI2cTOezWjz+HCGtZ6Lzi9Qt3x2AG7T+6jvXKPyL+Gu73CwPECnl8Th4Pnyoe+4hhCQnE9OF5AdEHtmF6HEEdzqdYAjhewL2WI5cCnF7CCX53N6gysh7EN8Pt/rJzwDSRJwiyfCHx7yPVa7zltci+tM+DzoAyklDbI1nKry2zFNA89vM4Mo8wpIU5ka1wJOF4YfCNfVyurzX7yS/UGdqNQd1YzvqWyz+EFB7Nwv6/rtd5z2uSulHk7UvHs6lith0GIquZuScbza+IGf1La9gGnRlTTdIV1ewpf0ufw4bRycLyAomuu1XqPkvsIbY5lVzC1rV1aD4UQVbR0mjFpoQ4rQgtsP0mSWMONzY+pdyN1IMH/BvzHA6brrf+uNrFer7sSXav1HiX3EeqpiHc8cxgV8QhxAmcuVHU3vxhkj0dFGrtqT9+p3sAGUp7CxpG2vc/hJ1dE45M9rrXDnJL7CImihHu9w/H94fNaD4UQVXx3+Dzu9Q6HVRzkivzkF6wMgFHjqQ9JArY+DQTe16c5iNvxHMxc4lo7zCm5j8JXBzLxgAveoCGuxypKuMcrDN8HD3Ix09nEVsic+Ua9gQ0m5yi7ei8K7T0kZFe73A5zSu6j4Ko3aIjr6anPcja7yvaTUjazZFp9Qb2BDcZqBgJmAHte7T3U2G4afjVLJ0HJfRQqmzvB8QJ2JLjWDRriepaHFGDyQh1aOs0DP0GSgA0PsqkQe5Kwmr3h1OT2HnpxbTze2eo6O8wpuY/S0ytj8N9d57QeBiGKen5NHN7dOkiNmCtJLIlm7lVvUMPR0Qj4/qXPmvtl3a33xrqZ0VFQch+MJAFNZUDuMba9+Yaqc4tO5mLG4hCYLK5zg4a4lpI6tit1e3z/Tke9js1nO0NvWHpoN85+D3jf0tu/NaawFhwvIL7YNVrvUXK/UXs9UBQGRPsB+94Clk9kVyU9kX+696mheTXgeAGppQ3qjY8QFXmfzcfkhTrUtdnoldrewGq2Cz+qO7Dhqi9mf7cx/gBY670p7jr46wdZr+9EXDe5Gw2sc3riOuDIf4A1M29I5L8HNj7MPtKl7QAqM1miv6HRb0unGRPdBKwKK1RmfIRoqMtsxV1Lw/DlgUzbT0oKZH8v1/LUG9hI7Z8DrJgMmNmmwzmbk/FKYILGg1KHayR3q5l1bEnfCZz6kiXupTddT+ZrZrIEn7iOJXyjof9rnPmW1c0wX6+t8cbGRLwxnEbBhDiYoxlXwfECkktsfDKVJGDdvQOW2bUrpTHsbzxrHwBgbQRrvdfc4fyt95w3udfkssa5258BfP50PZEvn8imXKL92BRMe/3wXq80pt/UTEBYISa6CbZXEhDioF7fkIh/rIqxvZejNJb9PZw/qO7ARkqSgI2PsOhuqcnxAkJynb/1nvMm96Iwdrd85wusWlzucXZzdLQbj6wWYPkk4Mh/ew+lljZ0/6LUjO41CbFDPSU2dg621PfIf1gNF7MDNMHIDGJvRKWxMFtF3LE4BB4nnb/1nvMmd6ulX0/FMTvzLXvDMLFmHyaLiBmLQ7DoZO4QX0iI43A7no3pi/S2P5EaagGvm4EQN3UHNlrmLjbvfmAuAOCj3WmY7QKt95w3uSuh56No/qneQx+5cI9G4nxau8yYsTgEPx8dZLdpfAD7O6hzoMUE0X5szPWXsD2+dOja9E6AkvtI9E7N/Kf30M7uHo1Xm0bXuo8Qe7I3uQwcL+BChY1OSqIIrLkT2PWSugMbK0MtW/Mu/ICL1a3geAFHnLz1HiX3kTr7XZ+pmaJrrEfj4bRyjQdGyNhIkoRnV8cOvlTwUgS7As45qt7A5HLyC8D3LxDbG3Gfdzi+c/LKrpTcR6pnaibvJAD2B/Hgsgh8Ndh6YEIcQFr3SpJBL1QOvc9WnFlsbGyyZzU57G83YQ2+Ppjl9JVdKbmPlNXCbs7cMDXzfTCrdy0OVu+aEDv3zaEszPQMRYfJxkKE1mpg6R+AsEXqDkxOe14BAmbgcArrqHap1nkru1JyH43fTM0cz2QbPnIrWzQeGCGj02AwYqq7Hp6nB9ltGrucXfk2lKg3MLkVhgCe41CfcgAcL2C3E7feo+Q+Gpfj+kzN1LZ2geMFbI514F964tJ6egMX2+pRIFqBgDuAva+pOzC5iSLbWbttNp74NQrz9zpv6z1K7qMhWtnUTPCHvYeeWx2HD7anajgoQkZHFCU8sTwac7cMUuu8KLTPBY1DO7cN8ByHTUH7MdPTeVvvUXIfrbPfd0/NsFKnXmfyMdVDjy6za9SKJs6jpxTu6QuDdFs6MBdYMYXVaXJ0RgPgfxuqts0FxwvIctLWe5TcR+tyfPeVzAkAQHQB+wNJKB5mrRpC7MT8vemY5RNuuzdBcwUrtBfppe7AlBS+GNLSm/Aovxsboi9pPRpFUHIfLdHKrmS6p2bajaxWtJ/+osYDI2T4qpo7MdFNwPKQQWqcR/myMthNV9QbmNJargJL/4Bjfv/Be9sG6TTlwCi5j4XwA+v63j01M2dLMl5aF6/xoAgZvoCwQkxwE1DRaGOHtdUCrJrOKqk6myP/RZf3X3GPx3GnnE6l5D4WPVMzuccBAIGRxeB4AY3tzl8rmjg+s1XEA74Rg/cCvniW/Y4XCOoNTC1X0wHPcfB0/9opp1MpuY9F79TMvwEAWeVN4HgBZwa7MUWIndDnVIPjBURevGb7SUH/AlbdLn+FVTth3fZPXFkyFT8cztB6KLKj5D5WN0zNWKwiZnqG4pej2VqPipAhvb89BY/6R8Fqa2d142U21x69TN2BqSnvBOA5Dp+6L0V+VavWo5EVJfexKkvoMzXzWVA6HvWPcuqaFcTxldYZwPEC1kcV235SmAcrN9DqxJ9ErRaIK6ch2vMfmLfDufapUHIfq56pmcPzAABBKVfA8QIu17drPDBCbPM5m4/JC3Wobesa+AmmDtZpqXvK0amFukNc+kfczR9CXFGd1qORDSV3OQg/sqkZowGX69vB8QKCksu0HhUhA+oyW3HX0jB8uX+QSqY9rekuu8Dqr+pswHMcVvr+jBfWxjtNAUBK7nLonZo5BkmS8Kh/FD514poVxLEdy2CF7pJKbKwQkSRg8+PAhodG33PYkUgSsOEhNKx7Ghwv4HjmVa1HJAu7T+7jx4/X+ns0NNEKrJzaOzXDH8t26poVxLG9sTERs1fF2L4vVHGOXaykbVd3YFrqbh04f+0RPOIX6RTr3u0+uTvElTsA6H4CfP4EGA04c6EKHC8g00lrVhDHlVfVAo4XsCNhkFK3x+YDy/4GGJ231nk/zRWA5ziUn1jqNBVeKbnLpSyxd2qmsd2ECW4C1kUOshKBEA0sPJGD6Yv0aOmwUQCsp9eo7md1B2YPdr0EBM7Cx7vOYaZnKJocfDMiJXe5iFZg5TTg8AcAgJcD4zFnsBKqhKisrcuMGYtD8NORC7afFLeCXaTUFak3MHuRsQfwHIcrOQmY6CbA60y+1iMaE0rucrphasZfX4Ap7jq0G51zZx9xPEHJZeB4Aecrmgd+gtUCBMwA9ryq7sDsRWcz+9Si58Efy8YUdx3KG2zU3HEAlNzldCWptzN8QnE9OF5AVMEgW7sJUYkkSXhudRxeDoy3fSP14hn2+3vxrLqDsyeH5wErJuNaswG3LwrB1weztB7RqFFyl5MosqmZQ++jy2zFNA+9w3+0I84hvawRHC/g0Lly20/a8wprpeekdWSGpadQWnEEAsIKwfECLtj6pGPnKLnLTfdz99RMG+btSMWzq2O1HhEh+PZQFmYuCUWHyUbiritkSS1upboDszcWI+B/G3BsPgxGC2b5hGPulmSHLCdCyV1uN0zN9DQdvtZqY4s3ISpoMBgx1V2PJadybT9J9xObbzY4z/b7UTvzDWuhaTT0lhMZtHKmnaLkLrcbpmZyK9ma4mMZzrHjjTimLd0XGUXXbKxbN7axde3HP1V3YPaq5wItOxhmq4jZK2Pwz4BYh9uUSMldCbqfAe9bIXa24l7vcHx/+LzWIyIuShQlPLkiGnM2D7Is99w2lsyuUskMAOwCbfVMYN+bAICQ3BpwvICDg92vsEOU3JVwJbl3auarA5l4wDfCIefsiOOLLaoDxws4db5y4CdIErDhQWDLk65RR2a4Ir1YU3BDLSRJwlubknC/b4TtexZ2iJK7EkSR9Z089D4Op5WD4wUU1rjQVm5iNz7dm477vMNhtNiolXI5jl2IZO1Td2D2rraAfV9SNgEAMq6wLmtrIxxn1zkld6XofwG8b0VVbd3QtTwIUUB1Sycmugnw1xfYftLhecCvHGDuVG1cDmPLE8DWp3r/93/7MjBjcQjq2oyaDWkkKLkrpTyl+6bMETy9MmbwJsSEKCAgvAgT3ARUNNrYZdlSyTothS1Sd2COInlDn1IMl+vbMXmhDh4nczQe2PBQcleKKLLGwofex6KTuZixOAQmi2PdbSeOy2wV8YBvBP4z2EVFlA/rkdpUptq4HEpbDZt3j/LpPbTkVC4mLdThUq1Bw4ENDyV3Jel5wPtWRJy/BI4XkFraoPWIiIsIya0GxwsIz7exPttiYu0hD8xVd2COJugNYM3M3pvN9QYj/r4k1CGa8VByV1L31ExHxkFMdBOwKqxQ6xERF/HB9lQ84hcJq62WcTlHe7fZk0GcP8i+T+UpvYfWRxWD4wWklTVqOLChUXJXUs/UzMH38MbGRLy+IVHrEREX0NPHN3CwfgI7ngXW3cN+R4ltxjbWH/ns972HOk1WPLgsAm9sTLTrJc6U3JXWPTWzXpeBiW4CWjptNEkgRCa+Qj4mL9Sh1lbZi+6G0EjeoO7AHNXRj9mKIsv15h3BaRXgeAG6nGrtxjUESu5KK08FPMfhUsQOcLyAkNwarUdEnJRVlBCWV4O7lobhi/0Ztp94+mt2NdpJbSCHpSiMvRkW6HoPWUUJz66OxVMrou12oQQld6V1T82IB97BjMUhDrOMijiO5g4TtsSW4LFfo8DxAh72i0R+VevAT+5sYon99NfqDtKRWc3A8klA8Id9DkcX1ILjBexJKtNmXEOg5K6GEDfA+xZ8sTMGT62I1no0xEkU1LTC7Xg2pi/Sg+MFzNmSDH1O9eAFrpLWs6vQ6mz1BuoMuutFoaul95AkSXhvWwru9Q5Ha5f9TbdScldD99RMzJH14PhBNpUQMgSLVURIbjXe2ZoMjhcwzUMP/li27Sv1G4kisPZuYMdzyg/U2VzNYG+KmUF9DudcZZVfV4QOsgtYI5Tc1SCKQMAMGHa/PXQ3HEIG0NRuwqaYEjzqz6ZeHvWPwubYEjS1m4b+4h7F4b0F7cgISRKw7l5g98v9HvrmUBameehR3WJfJRwouaslZCEk71sw2/cUvjyQqfVoiIPIq2rBz0cvYJoHm3p5d2sKQnJrRldbfP8ctnHJMoI3BHJdzK9sR29L3/4MFY0dmOqux09HLmg0sIFRcldLxTnAcxz2b12Oe7zCINraXEJcntkqQsiuxpzNbOpl+iI93I7noKBmGFMvtjReZokpyle+gbqaxlL2ySdhTb+HfIV8THATxvYzkhkld7WIIhBwB6o3vQaOF5Bu57vbiPoaDEZsiL6Eh5ZFguMFPPZrFLbFlaKlQ4abdWEerEhYa9XYX8uVbX8G2PhIv8PNHSbc6Rk6eC0flVFyV1P31Mwjnifwv32DrEMmLsVkEeF2PAdTu6dePtieivD8a7ZLB4yUuZNtwgn+tzyv58p6ulbV9O9Huy2uFBwvIPFSvQYD64+Su5oq0gDPcTgbFIAJbgIu17drPSJiBzZEs8JybsdzUGyrz+lYZO1jCelyvPyv7Wra6wGvPwLhi/s91GW24n7fCMy3k6JilNzVJElAwB0w7n0bU931cD9BG5pcXUVjB6Z56JX7JCdJrOnEhoeojZ5cDsxlNaMGqMvjczYfU9x1I1vFpBBK7moLdQe8b8HSI4mY6qF3mK4uRH6SJOGj3Wm4Y3GIcsvouj8tIm27Mq/vinKPdX8Siuv3UF4VW/celHJFg4H1RcldbZVsM0RtzGZMoDLALi0ktwYcL2B7fKlyJzn+KbDsb6y6IZGHqYN9T0992e8hSZLw3Oo4/Guj9hVgKbmrTZKAjQ8DW5/Gp3vTcdfSMLQbHaejOpFHu9GCh/0i8fyauNGtWR8OQx3gfQvbOk/kdfILwO//Ddh7dnNsCTheQJnG99QouWshZRPgOQ75WUngeAG7Eql5tqtZprsIjheQcUXBJbFxK/v0ACUyKo1h39u8E/0eqm7pxAQ3AavDtf2+U3LXQkcju6LS/4K3NyfhUf8omJW6eiN2p6CmFZMW6sAfU7B4l9UCBNwB7HlVuXO4MtEKrJoOHHx3wIff356CJ1dEa9rMg5K7Vo5+BPiPR1ROOThewKnzlVqPiKhAFCW8tSkJ93qHK7ui4uJZdmV58axy53B1YR5sWWR7/97IR9IrlP9kNgS7T+7jx4/X7JujqJJowHMcxOwj+MeqGLywNt6uW3YRefR08AlOr1D2RHteZVfuVrqfo5iaHJsrkQxGC6Yv0na5s90nd6e9chdF1lV9z6u9f/DxxXVaj4ooqKndhHu8wvD25iRlawvVFbGkE7dSuXMQtjhiw0M2SygvOJiFu5aGadapiZK7lmJXAJ7jYKwrwQO+Efhge6rWIyIK+uVoNiYv1KGwRuFlibqf2T0dA10sKC4+gL2RNvZfFBFdyDo1heZp01qTkruWWiqBpTcBkd69y6dyK1uG/jricNLLGsHxAvx0F5U9UUcjW4N9/FNlz0OY5gqW3GNX9HvIYhUxyycCnwdpU0eKkrvW9r8NrJqO1o5O/H1JKL4+mKX1iIjMzFYRz6+JwyN+kcruaZAkVhzM62bgWp5y5yF97XoJCJw1YHkHrzP5mOqul6ey5whRctfaxTPsnb8oFMt0FzFpoY7a8DmZnmqBin88v3CY/S7FByh7HtJXxh72fa/s34Qnt5KVI9ifqn45AkruWrOagRWTgUPvo7qlE1PcdfA8TVddzqKquRMzFofg491pyq6GarkK+N3Gbu6JVuXOQ/rrbO7et8L3e0iSJDwTEIu3NiWpPixK7vYgbBFrpNB2DT8euYDbF4XYRVU5MnafB2Vg+iK9sp/GRBHY8wqw7P8GvLFHVHB4HrtIG2DpaU9J5/IGdT+RU3K3B/XFve27iq61geMFrIss1npUZIyiC9hqiQ3Rl5Q9UfJG9vuTsUfZ8xDbejaNFUf0e6iyuRMcL2BthLp/05Tc7cXOF1h39e4ysPd6h6PLTB+vHVWnyYrHl0fhnwGxyq5zri0AvG8FDrxD9dq1ZDEC/uOBY/MHfPidrcl4emWMqhsVKbnbi/MH2Tt/WSJSSxvspiY0GZ2VoYXgeAHJJf23psvGYgI2Pw4snwQYapU7DxmeM98Cvn8BjIZ+D/VsVMwqb1JtOJTc7YWpg5UQPf4ZJEnC6xsS8eSKaPn6aBLVXKo1YIq7Dt8fPq/siSK9qX6MPbmSxH4e57b1e6ity4xpHnosPtW/96pSKLnbk7PfAT5/Bjqboc+pBscL0OVUaz0qMgKSJOHdrSm40zMU9QYFu2xVnGMb4E72bxhBNCKKbLXS0psGvP/x1YFM3OOlXjkCSu72pCqrtxCRVZTw1N4GL2MAABGtSURBVIpovLY+gQqKOZCTWZXgeAH7lJxSMxqAtXez2kRdrcqdh4yc0QAE/ev6rtUb/najCq6B4wWE519TZSiU3O2JJAGbH2MNjQHsT72i/LwtkU1LpxmzfMLx2oZEZQuDnfkW8Pw9UKZ9KzcyAKsZOP4ZS/DCj737DsxWEfd5h+OL/eqUI6Dkbm9St7JfiuoL6DJbMcsnHP/ZdU7rUZFhWHQyFxPdFK4PVBTGfj/CFil3DjJ2osh+Rp7jWEkIcxcAwPN0HqZ66NHSqXw5Akru9qaziS1tE34EAARGFoPjBRTU0Mdve3ahohkT3ARldxe3NwArpgAbH2FL74j9S1rPEvzul4GuFlyoaAbHCzh0rlzxU1Nyt0fH5rOt5OZONHeYcPuiEHwfrPDKCzJqVlHCK4EJeMA3Am1dCl2RSRLbBel1M2sSQRxHdjDr2LTpMUit1Zi9KgZztiQrflpK7vbocjx7t79wGACw9EweJi/Uoaq5f6d1or09SWXgeAFnLlQpd5ILh3p3MRMHdCkC8P0rsGYmgoRIcLygeIFASu72SJLYaohdLwEArjZ1YNJCHXzO5ms8MPJbta1dmLkkFPN2pCq3qqm5gu2B2PkCFQVzZJUZwPKJsP46Ea+4BWJ9lLLlCCi526v4VexKraEEAPDNoSzcsThElRsxZPgWHMzCVA89Lte3K3MCUWTztcv+D2gqU+YcRD31l4A1M9G19E/4+dfVii5zpuRur1qrWaXICE8AQF4Vqwu9MUbhIlRk2BKK68HxAlaHFyl3kuQN7E0+M0i5cxB1tdWgadUDMC/5A65E71LsNJTc7dmBd4CVU9m6WQDzdqTift8IKihmBzpMFsxeGYOnVkQr9/OovchWTh18l4qCOZmW5gakLH6YvXEnrVfkHJTc7VmBjv3wCwQA168U1VhGZU86TAq2phsFk0XEhzvPYaKbgITiemVOYjGxDW3LJ1Gjaye1ICgZEZ7PXd+3IMpbloCSuz2zWoCV09gVPFjdkpfWxWP2qhhld0DaibSyRny8Ow0T3OxnOkoUJSw4mAWOF3BQyTfZSK8+b+zE+YTnX8NE/gyu7v+C/ayPf9b7KV0OlNztXcRSVoiolS2zO32hChwvIEzpfpwaEUUJEfnX8OamJHC8gHu8wjBnSzI4XsDm2BJNxyZJEpacyr1+78NQO2DnnTErT2U/81NUFMyZmSwi7vEKw1f7M1gdGs9xwL43BywZPBqU3O1dQwn7ocetBABYrCIe+zUKb2rQk1FJJouIoxlX8UxALDhewKP+UdiTVIZOkxUWq9h7tbw1TrsEvzaC7Rb2OZsPqUBgCXjZ34D9bwOJ61iD5LEuVTQagLV3UVEwF7H4VC6meejR2mVmlSSX3gRsm812I48RJXdHsPtl9gffPSe3O/EyOF5AelmjxgMbu3ajBdvjS/GwH9vY8fyaOJzMqoTZ2nf+0WIV8dWBTHC8gO3xpaqPMyiZbVT6IfgCxJp8tjRx8+OsTHPgLPYG7DmOrUc/MJfdJKu+MPJkf3oBKwp2xbnevMnAssqbwPECgtMq2IECAfD5ExB4H9A0tsqilNwdQXYwSxyX4wCwG4x3e4Vh/t50jQc2eg0GIwLCCnHX0jBwvIA5W5IRXVg76Lpfi1XEl/tZgt+RoF4j6NMXqjDBTcAne9JgMTSwDWYrp/ZOlQEA2mqAnKMsOa+793qy9x8PHHyP9TmtyRn8pllhCPua8MXK/6OIXZAkCU+vjME7W28oR1CeAvjfxu631Yy+uQcld0dg7mQ/7GOf9B4KCC8Cxwu4VCvP/JxaKho7sPhULqYv0oPjBczfm46MK8NvPWa2ivjfvgxwvIDdicon+NiiOkxx12HO5mR0GY3A3tcB71tYs4zBtFSyN+VTX7E3g55k/ysHHHofSN0CXMu7nuzb61lRsE2PUlEwF7Ouuzhg5Y3lRWovAqtu793nMhqU3B2F8CNb89zBpmIaDEZM89Djl6PZGg9sePKrWvHNoSxMWqjDFHcdfjpyAZdq20b1WmariM+C0sHxAvYml8k70Btkljfh9kUheGFtPJsTDVk4+g1FzRWsT+7JL9l8ek+yXz6RFQTb9SJ70xjDlRpxTOUNHeB4ARuif7MizFA7puWRlNwdRXU2SwapW3oPeZzMwVR3PWpaujQcmG2SJCG5pAEf7jwHjhdwx+IQ+JzNR3XL2AugmSwi5u9NV6yReNG1NtztFYYnV0Sjrs0InD/Avv/6X+Q5QdMVIGs/cOJzIOCO7s0sgfK8NnE4b21Kwj8DYmUtR0DJ3ZFseZJ9bO/+Baho7MBUdz1+PHJB44H1F55/Da9vSATHC7jPOxzro4rR0iFvXRyTRcQne9LA8QL2p8qX4K82deChZZF4wDeCVe67ms4+Ne15RdZ1yL0kiU3LEJfV03VNzkYvlNwdSdoOdoVXmdl7yE9/ERwvIPtqs4YD66tnLf7jy6MQlFymaLkEo8WKj3anybapqN5gxOyVMbjTM5Q1SGmtZje21tzZOyVGiNxaOsyY6q6H1xn5Kr9ScnckXS2Az59ZD81ubV2sb+dbm5LsopG2wWjBg8si8HJgfL/ljEoxWqz47y429XM4bfQJvq3LjJcD4zF9kZ4tMzV3sTXHvn9lNz8JUdDnQRmY5RMBi0x/N5TcHc2Jz9laatP1ErOHzpUr3yximJbp2CeJzPLhr4CRQ5fZig93nsMENwHB6RWj+vp3t6Zg8kIdogtq2VTJif+xT0oXzygwYkL6Cs2rAccLiC6sleX1KLk7mitJLOGcP9B7yCpKeGFtPB71j9K0YmTxtTZMXqjDz0e1uQfQZbZi3o5UTHATcDTj6rC/znLD6puTWZXsYE+p3Rh/hUZLSF8mi4i7vcKw4GCWLK9n98l9/PjxsvxDnYYksd1rO5/vczi5pAEcLyAwUtnuLraHJeHdrSm40zMUDQbt1ml3ma34YDtL8Mczh07wkiThl6PZ4HgBu3rWzZdEsW3ghz+QvVIfIYNxP5GD6Yv0MBjHXrPI7pM7XbkPIGENu6qs69sk4vOgDNy+KATXWtVfGnmm+yZqkILrzoer02TFe9tSMNHthitxG/z1BeB4AQFhhexAQwnbVbrxEdkKOBEyXBlXGsHxAo6MYmrxtyi5O6K2a6ybetiiPofLG9jSyO+Dz6s6nJ6bqC+ti4fVTkoRd5rYHPpENwGnzg+c4LfGlYDjBbifyGE3o7tagfUPsF2k1NKOaECSJDy5IhrvbUsZ82tRcndUh94HVkxmTR1u8GsIuxK9UKHe0ki/7puoIykjoIYOkwVztyRjolv/m81H0ivA8QK+PJDJ3pBEkdXNX/oHoDRWoxETAqwOL8IEN2HMm/0ouTuqojA2NZN/us9hg9GCWT4ReFOlpZGXatlN1J/scCMVwBL8nM3JmLRQByG7GgAQlleDSQt1mLcjFSZL95x6lE+/HcCEaKGsvl2W/gWU3B2VaGWFhfa91e+h4DR2VXpa4aWRkiThvW3sJmq9UjdRWypZw5K8E6yA2ii0Gy14e3MSJi3UYVVYIaZ66PH6hkS099y0yjvBEvupr6hXKbEL/9qYiOdWx43pAo2SuyOL8mGrOhr7Vke0iqwd3yN+keg0Kbc08mx2lbLFuwr1bP77xlrpp75k0yYjrJNuMFp6uzv9MyAWTe3d01nV2YDvX4Adz1I1RmI3glJYOYK8qtGXI6Dk7shaKlknoJ0v9Et2qaVsaeQ6hZZGthsteGhZJF5cq8BNVIsRCHFjCX3zY0BdIVAaA5z8gv17PcexTy1hi0ZURbGty4z1UcXXC6211wOrZ7LXarsm77+BkDFoajdhirsOPmdHX46Akruj66lWGL+q30Nf7GdLI5WoGtlT0ybjisz1VhpKgC1PXK/A+NuraVMHkHuMdTvy+iN73saHgYTVQMvwNy7BagZ2vcS63txQq4cQeyFkV+NqU8eov56Su6OTJCD4Q5boqvrubKto7MBUDz2+Oyzv0shLtQZMXqiTvxpl9hHWvs5/PGs3NpT2BuDcNmD7M91TN79nLQkz9gCdQ6wWEn5gX5MdLM/YCbEzlNydQUcjm1oInMWubG+wvHtpZJZMtV4kScIH21MxU86bqKZ2NpfuOY7tvB3JFXiPxlIgdjnbves5jpXoPTwPuHi2/9V/+i72nN/sEyDEmVBydxalsezK9ex3fQ4bjBbc7xuBNzYmyrI0UsiuBscL2JNUNubXAsDmzNffz8Ye5QNYx7jtWpKAygxAz7N9AD19TM98w+rylCWyTzn73hx582pCHAgld2cS5sGSWaG+z+Hg7g07tnZqDle70YKH/SLxwtr4sZcllSRWn977VtZsujRmbK83EKsFKI4Ajs1nK2J6Vt0E3jf0tA0hDo6SuzOxGNnqkuWTWP/FbqIo4ZXABDzsF4kO0+ivjHt2v6aXjfEmamczmzLxHAcE/Qsw1I3t9YbDaGDz6yf+B9RfGvr5hDg4Su7OpraArQDZ/3afDTlpZawg0ZqIokG+2LaSOgOmuOvwQ/AYb6JWpLHlh15/BBLXUtVFQhRCyd0ZpW5lV8XntvU5/OWBTExfpEdV88h2ekqShHk72E3UurZR3kQVRVbN0uuPwJqZrC8pIUQxlNydkSSxG4Y+f2IbgLpdbWJLI789NLJmAPocdhN1d+LloZ88EEMtEPQGe8MJ/pDmuwlRASV3Z9V2DVg+Edj8eJ/KkStDC0fUBq/DZMEjfpF4fk3c6G6ilkSzG6Y+f2JLEKl2CyGqoOTuzAp07Go5fHHvoXajBQ/4RuD1DYkQh1E2oGedfNpIb6JaLUCkF1viuP4BajBNiMoouTu7M9+wBHs5vvfQ0Yyr4HgBJ7IG3yxU2n0TdcTNP5rLgR3PXa+0eEMzb0KIOii5OztTO1vXHTAD6GRTMaIo4dX1CXhome2lkb03UZeM8CZq3gnA7zZW4CvnqBz/AkLIKFBydwWVmWyVypH/9s55p3cvjQwIH3hpZEguu4m6M2GYN1FN7cDpBexqfdvsfmWICSHqouTuKuJWssR74VDvoa8PZmGahx6Vv1kaOeKbqDU510sIRCxlFRcJIZqi5O4qRCur+77sb73NnyubOzHNQ48FB/sujVwRym6inrs8xE1USQJSNgPetwArp1HvUULsCCV3V9JczroZ7Xiut2hWQFhhn7rspXUGTHXX4/uhygS31wP757BPAwfmsvK7hBC7Qcnd1WQHs4QctwIAm4J5cFkEXlufAFGU8O+d5zBzSShq2wZp8FEaw67UvW9lu2Fp7TohdoeSu6uRJODoR+wGa2UGAOB4Jlsa+fXBLHC8gB22bqJazUD4ku616/ezuXZCiF2i5O6KOpuBgDuAdfcCRgNEUcJrGxLB8YLtm6iNpWwVjOc4tnbeNPr2X4QQ5VFyd1VlCewK/PQCAMD5imY8sTx64HK+2cHsRqz/bUD+KZUHSggZDUrurix8CbsSv3gWAPp3ajK2Acc/u97+rrlCg0ESQkaDkrsrs5iALU8Av04A2mr6PlaZCay7B1h6ExDjP/b2d4QQVVFyd3V1RYDPn1lHJEliddcT17IbrgF3sL6jhBCHQ8mdAGnb2dRLtB+w93X234fn9daiIYQ4HkruhF2xH5jLkrrPn6nuOiFOgJI7YdrrAf0vrAcrIcThUXInhBAnRMmdEEKckN0n9/Hjx2v9PSKEEIdj98mdrtwJIWTkKLkTQogTouROCCFOiJI7IYQ4IUruhBDihCi5E0KIE7L75E5BQUFBIXtoPgAKCgoKCvlD8wFQUFBQUMgfmg+AgoKCgkL+0HwAFBQUFBTyh+YDoKCgoKCQPzQfAAUFBQWF/KH5ACgoKCgo5A/NB0BBQUFBIX9oPgAKCgoKCvlD8wFQUFBQUMgfmg+AgoKCgkL+0HwAFBQUFBTyh+YDoKCgoKCQPzQfAAUFBQWF/KH5ACgoKCgo5A/NB0BBQUFBIX9oPgAKCgoKCvlD8wFQUFBQUMgfmg+AgoKCgkL+0HwAFBQUFBTyh+YDoKCgoKCQPzQfAAUFBQWF/KH5ACgoKCgoZI7/D8koGqAhx7zqAAAAAElFTkSuQmCC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNEkAMxnz8Mq"
   },
   "outputs": [],
   "source": [
    "### Make Predictions ###\n",
    "\n",
    "# trainPredict = model.predict( )\n",
    "# testPredict = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbnRqEv9z-he"
   },
   "outputs": [],
   "source": [
    "### Scale Back Predictions ###\n",
    "\n",
    "# trainPredict = scaler.inverse_transform(trainPredict) # scale train prediction back with scaler.inverse_transform()\n",
    "# trainY = scaler.inverse_transform([trainY])  # scale train labels back with scaler.inverse_transform()\n",
    "\n",
    "# testPredict = scaler.inverse_transform( ) # scale test prediction back with scaler.inverse_transform()\n",
    "# testY = scaler.inverse_transform( ) # scale test labels back with scaler.inverse_transform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdBWzmE91G6_",
    "outputId": "fa1e0b3f-0ef2-4d14-c0f3-355941a9a556"
   },
   "outputs": [],
   "source": [
    "### Calculate Root Mean Squared Error (RMSE) ###\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error # Import mean_squared_error from sklearn.metrics\n",
    "\n",
    "# trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0])) \n",
    "# testScore = \n",
    "# print('Train Score: %.2f RMSE' % (trainScore))\n",
    "# print('Test Score: %.2f RMSE' % (testScore))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "txdu8q7l1aju",
    "outputId": "31540d81-99fc-4833-a9f8-c96e445c1d77"
   },
   "outputs": [],
   "source": [
    "### Plot Observation Data and Prediction Results with TEST dataset ###\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(testY[0]) # Plot Observations in Test Set\n",
    "# plt.plot(testPredict) # Plot Predictions in Test Set\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O49Ug-FhtCg8"
   },
   "source": [
    "## 2 - Build an LSTM model to conduct sentiment analysis ##\n",
    "\n",
    "### 2.1 Prepare the data (13 Points) ###\n",
    "\n",
    "Prepare IMDB data for reccurent neural network training.\n",
    "\n",
    "**Tasks:**\n",
    "1. Load the data from IMDB review dataset and **print out** the lengths of sequences. **(3 Points)**\n",
    "2. Preprocess review data to meet the network input requirement by specifying **number of words=1000**, setting **the analysis length of the review = 100**, and **padding the input sequences**. **(10 Points)**\n",
    "\n",
    "**Hints:**  \n",
    "1. You may load the IMDB data with keras.datasets.imdb.load_data(num_words=max_features). Here. max_features is set to **1000**.\n",
    "2. You may use keras.preprocessing.sequence.pad_sequences(x_train, maxlen) to pad the input sequences and set maxlen to **100**.\n",
    "\n",
    "**Note:**\\\n",
    "We train the built LSTM-based model with ALL training data; the **validation set** (aka **development set**) is set with the **testing set** for model evaluation. This split is common in the application with limited sampled observation data, like NLP problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UI4ki461S2V3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "### Set random seed to ensure deterministic results\n",
    "import os\n",
    "seed_value = 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(seed_value)\n",
    "   np.random.seed(seed_value)\n",
    "   random.seed(seed_value)\n",
    "\n",
    "reset_random_seeds() # randomly set initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvV1Sv2a18SM",
    "outputId": "becf27fe-d121-4b3b-abc0-809c4879883a"
   },
   "outputs": [],
   "source": [
    "# Prepare the data here\n",
    "\n",
    "# max_features =  # Only consider the top 1k words\n",
    "# maxlen =  # Only consider the first 100 words of each movie review\n",
    "\n",
    "# (x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data( ) # load IMDB data with specified num_words = 1000; testing set is set to validation set.\n",
    "# print(len(x_train), \"Training sequences\")\n",
    "# print(len(x_val), \"Validation sequences\")\n",
    "# x_train = keras.preprocessing.sequence.pad_sequences( ) # Pad IMDB training data with specified maxlen=100\n",
    "# x_val = keras.preprocessing.sequence.pad_sequences( ) # Pad IMDB validation data with specified maxlen=100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_JFQeWK18SR"
   },
   "source": [
    "### 2.2 - Design and train LSTM model (25 Points) ###\n",
    "\n",
    "Build an LSTM model.\n",
    "\n",
    "**Tasks:**\n",
    "1. Build the LSTM model with **1 embedding layer**, **1 LSTM layer**, and **1 Dense layer**. **Print out** model summary. The embedding vector is specified with the dimension of **8**. **(10 Points)**\n",
    "2. Compile the LSTM model with **Adam** optimizer, **binary_crossentropy** loss function, and **accuracy** metrics. **(5 Points)**  \n",
    "3. Train the LSTM model with **batch_size=64 for 10 epochs** and report **training and validation accuracies over epochs**. **(5 Points)**\n",
    "4. **Print out** best validation accuracy. **(5 Points)**\n",
    "\n",
    "\n",
    "\n",
    "**Hints:**  \n",
    "1. Set input dimension to **1000** and output dimension to **8** for embedding layer.\n",
    "2. Set **unit_size=8** for LSTM layer.\n",
    "3. Set activation function to **sigmoid** for Dense layer.\n",
    "4. For validation: the outputs for first epoch should be close to（but maybe not exactly following） the statistics below:\\\n",
    "- **-loss: ~0.6402 - accuracy: ~0.6187 - val_loss: ~0.4645 - val_accuracy: ~0.7995**\n",
    "5. The model summary is as follows:\n",
    "- Total params: 8,553\n",
    "- Trainable params: 8,553\n",
    "- Non-trainable params: 0\n",
    "\n",
    "**Useful Reference:**\n",
    "1. https://keras.io/examples/nlp/bidirectional_lstm_imdb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDqqgFt118SS",
    "outputId": "e8c03f08-bdd3-442a-d27f-3ad889f9ba73"
   },
   "outputs": [],
   "source": [
    "### Model design with Embedding and LSTM layers ####\n",
    "# inputs = keras.Input(shape=(None,), dtype=\"int32\") # This is an easy way to set an adaptive length for input sequence\n",
    "# x = layers.Embedding( )(inputs) # Embed data in an 8-dimensional vector\n",
    "# x = layers.LSTM( )(x) # Add 1st layer of LSTM with 8 hidden states (aka units)\n",
    "# outputs = layers.Dense( )(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n",
    "\n",
    "### Clear cached model to refresh memory and build new model for training ###\n",
    "keras.backend.clear_session() # Clear cached model\n",
    "# model = keras.Model(inputs, outputs) # Build new keras model\n",
    "# model.summary() # Print out model summary\n",
    "\n",
    "# model.compile( ) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n",
    "# model.fit( ) # Train the compiled model with model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vqvy2tdEw7J"
   },
   "source": [
    "### 2.3 - LSTM hyperparameter tuning (Bonus 15 Points) ###\n",
    "\n",
    "Boost the performance of obtained LSTM (aka vanilla model) by hyperparameter tuning.\n",
    "\n",
    "**Tasks:**\n",
    "Note: \n",
    "- All modificiations are directly conducted based on the vanilla model above (from 2.2).\n",
    "- For each scenario, **report <span style=\"color:red\"> BEST Validation Accuracy </span> and generate Training/Validation <span style=\"color:red\"> Accuracy plots over epochs</span>**. You may just paste the plot figures in the cells with **Markdown mode**, or leave the result after running. **Make sure it is already correctly shown in your submitted file.**\n",
    "1.  Scenario 1 (**5 points**):\n",
    "    - Add one additional LSTM layer (totally 2 LSTM layers).\n",
    "    - Modify the embedding dimension to 16.\n",
    "    - Modify the units of LSTM to 16.\n",
    "2. Scenario 2 (**5 points**)\n",
    "    - Add one additional LSTM layer (totally 2 LSTM layers).\n",
    "    - Modify the embedding dimension to 128.\n",
    "    - Modify the units of LSTM to 128.\n",
    "3. Scenario 3 (**5 points**)\n",
    "    - Add one additional LSTM layer (totally 2 LSTM layers).\n",
    "    - Modify the embedding dimension to 128.\n",
    "    - Modify the units of LSTM to 128.\n",
    "    - Increase analysis length for review data to maxlen = 200\n",
    "\n",
    "**Hints:**  \n",
    "For validation: the outputs for first epoch should be close to （but maybe not exactly following） the statistics below:\n",
    "- Scenario 1: **loss: ~0.5839 - accuracy: ~0.6524 - val_loss: ~0.4079 - val_accuracy: ~0.8198**\n",
    "- Scenario 2: **loss: ~0.5572 - accuracy: ~0.6911 - val_loss: ~0.3953 - val_accuracy: ~0.8244**\n",
    "- Scenario 3: **loss: ~0.5605 - accuracy: ~0.6914 - val_loss: ~0.3402 - val_accuracy: ~0.8560**\n",
    "\n",
    "- Summary of Model 1: Total params: 20,241; Trainable params: 20,241; Non-trainable params: 0\n",
    "- Summary of Model 2: Total params: 391,297; Trainable params: 391,297; Non-trainable params: 0\n",
    "- Summary of Model 3: Total params: 391,297; Trainable params: 391,297; Non-trainable params: 0\n",
    "\n",
    "You may follow the example from the reference below to add additional LSTM layer.\n",
    "\n",
    "**Useful Reference:**\n",
    "1. https://keras.io/examples/nlp/bidirectional_lstm_imdb/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xMSM_GQt_P8",
    "outputId": "d1e80c22-e19d-4940-a894-824d4ee3c152"
   },
   "outputs": [],
   "source": [
    "########################### Scenario 1 ###########################\n",
    "##################################################################\n",
    "\n",
    "### Set random seed to ensure deterministic results ###\n",
    "import os\n",
    "seed_value = 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(seed_value)\n",
    "   np.random.seed(seed_value)\n",
    "   random.seed(seed_value)\n",
    "\n",
    "reset_random_seeds() # randomly set initial data\n",
    "\n",
    "# max_features =  # Only consider the top 1k words\n",
    "# maxlen =  # Only consider the first 100 words of each movie review\n",
    "\n",
    "### Model design with Embedding and LSTM layers ####\n",
    "# inputs = keras.Input(shape=(None,), dtype=\"int32\") # This is an easy way to set an adaptive length for input sequence\n",
    "# x = layers.Embedding( )(inputs) # Embed data in a 16-dimensional vector\n",
    "# x = layers.LSTM( )(x) # Add 1st layer of LSTM with 16 hidden states (aka units); set return_sequences=true.\n",
    "# x = layers.LSTM( )(x) # Add 2nd layer of LSTM with 16 hidden states (aka units)\n",
    "# outputs = layers.Dense( )(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n",
    "\n",
    "### Clear cached model to refresh memory and build new model for training ###\n",
    "keras.backend.clear_session() # Clear cached model\n",
    "# model = keras.Model(inputs, outputs) # Build new keras model\n",
    "# model.summary() # Print out model summary\n",
    "\n",
    "# model.compile( ) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n",
    "# model.fit( ) # Train the compiled model using model.fit() with batch_size=64, epochs=10, and validation_data=(x_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Keod5xXkEKnx",
    "outputId": "5f45b1d0-307c-4cd0-b59c-343f2e2fda8d"
   },
   "outputs": [],
   "source": [
    "########################### Scenario 2 ###########################\n",
    "##################################################################\n",
    "\n",
    "### Set random seed to ensure deterministic results ###\n",
    "import os\n",
    "seed_value = 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(seed_value)\n",
    "   np.random.seed(seed_value)\n",
    "   random.seed(seed_value)\n",
    "\n",
    "reset_random_seeds() # randomly set initial data\n",
    "\n",
    "# max_features =   # Only consider the top 1k words\n",
    "# maxlen =  # Only consider the first 100 words of each movie review\n",
    "\n",
    "### Model design with Embedding and LSTM layers ####\n",
    "# inputs = keras.Input(shape=(None,), dtype=\"int32\") # This is an easy way to set an adaptive length for input sequence\n",
    "# x = layers.Embedding( )(inputs) # Embed data in a 128-dimensional vector\n",
    "# x = layers.LSTM( )(x) # Add 1st layer of LSTM with 128 hidden states (aka units); set return_sequences=true.\n",
    "# x = layers.LSTM( )(x) # Add 2nd layer of LSTM with 128 hidden states (aka units)\n",
    "# outputs = layers.Dense( )(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n",
    "\n",
    "### Clear cached model to refresh memory and build new model for training ###\n",
    "keras.backend.clear_session() # Clear cached model\n",
    "# model = keras.Model(inputs, outputs) # Build new keras model\n",
    "# model.summary() # Print out model summary\n",
    "\n",
    "# model.compile( ) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n",
    "# model.fit( ) # Train the compiled model using model.fit() with batch_size=64, epochs=10, and validation_data=(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdiZbuCQt_QC",
    "outputId": "58a03d65-1380-4f16-f6b1-f4c023daa121"
   },
   "outputs": [],
   "source": [
    "########################### Scenario 3 ###########################\n",
    "##################################################################\n",
    "\n",
    "### Set random seed to ensure deterministic results ###\n",
    "import os\n",
    "seed_value = 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(seed_value)\n",
    "   np.random.seed(seed_value)\n",
    "   random.seed(seed_value)\n",
    "\n",
    "reset_random_seeds() # randomly set initial data\n",
    "\n",
    "max_features =   # Only consider the top 1k words\n",
    "maxlen = # Only consider the first 200 words of each movie review\n",
    "\n",
    "### Model design with Embedding and LSTM layers ####\n",
    "# inputs = keras.Input(shape=(None,), dtype=\"int32\") # This is an easy way to set an adaptive length for input sequence\n",
    "# x = layers.Embedding( )(inputs) # Embed data in a 128-dimensional vector\n",
    "# x = layers.LSTM( )(x) # Add 1st layer of LSTM with 128 hidden states (aka units); set return_sequences=true.\n",
    "# x = layers.LSTM( )(x) # Add 2nd layer of LSTM with 128 hidden states (aka units)\n",
    "# outputs = layers.Dense( )(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n",
    "\n",
    "### Clear cached model to refresh memory and build new model for training ###\n",
    "keras.backend.clear_session() # Clear cached model\n",
    "# model = keras.Model(inputs, outputs) # Build new keras model\n",
    "# model.summary() # Print out model summary\n",
    "\n",
    "# model.compile( ) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n",
    "# model.fit( ) # Train the compiled model using model.fit() with batch_size=64, epochs=10, and validation_data=(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRu2xHOIt_QE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Homework_04_Solutions.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
